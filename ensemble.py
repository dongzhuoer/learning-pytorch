import os, sys, shutil, glob, re, time, argparse
import numpy as np
import matplotlib.pyplot as plt
import torch, torchvision
from PIL import Image
import utility
torch.set_printoptions(sci_mode = False)


# command line options -------------
parser = argparse.ArgumentParser(formatter_class = argparse.RawDescriptionHelpFormatter, description = "ensemble features generated by ResNet, VGG, Inception and DenseNet")
parser.add_argument("--data-dir", metavar = "PATH", default= "data/dogs-vs-cats/data", help = "data directory, contains input images")
parser.add_argument("-b", dest = "train_batch", type = int, metavar = 'N', default = 32, help = "training batch size (default: %(default)s)")
parser.add_argument("-B", dest = "valid_batch", type = int, metavar = 'N', default = 64, help = "validation  batch size (default: 128)")
parser.add_argument("--epochs", type = int, metavar = 'N', default = 16, help = "number of epochs to train (default: %(default)s)")
parser.add_argument("-l", dest = "learning_rate", type = float, metavar = 'R', default = 0.001, help = "SGD learning rate (default: %(default)s)")
parser.add_argument("--gpus", type = int, metavar = "GPU", default = [0], nargs = '+', help = "ordinal of GPUs to use, such as \"0 1\" (default: 0)")
parser.add_argument("--seed", default = int(time.time()), help = "random seed (default: time)")
args = parser.parse_args()

args.train_batch *= len(args.gpus)
args.valid_batch *= len(args.gpus)
args.data_dir = os.path.expanduser(args.data_dir)
torch.cuda.set_device(args.gpus[0])
torch.manual_seed(args.seed)


# preconvolute -----------------
class layer_activition():
    def __init__(self, model):
        super().__init__()
        self.handle = model.register_forward_hook(self.hook)
        self.values = []
    
    def hook(self, model, input, output):
        feature = output.view(1, output.shape[0], -1).cpu().numpy()
        self.values.extend(feature)

    def remove(self):
        self.handle.remove()

def pre_convolute(model, layer, data_loader):
    model.eval()
    feature, labels, device = layer_activition(layer), [], next(model.parameters()).device
    for input, target in data_loader:
        with torch.no_grad(): model( input.to(device) ).view( len(input), -1 ) # bacth is unchaged
        labels.append(   target.cpu().numpy() )
    return np.concatenate(feature.values), np.concatenate(labels)
# load data and transform
imagenet_mean, imagenet_std = ([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])
transform = torchvision.transforms.Compose([
    torchvision.transforms.Resize((299, 299)),
    torchvision.transforms.ToTensor(),
    torchvision.transforms.Normalize(imagenet_mean, imagenet_std)
])
train_data = torchvision.datasets.ImageFolder(f'{args.data_dir}/train', transform)
valid_data = torchvision.datasets.ImageFolder(f'{args.data_dir}/test',  transform)
train_loader = torch.utils.data.DataLoader(train_data, args.train_batch, num_workers = len(args.gpus), shuffle = False)
valid_loader = torch.utils.data.DataLoader(valid_data, args.valid_batch, num_workers = len(args.gpus), shuffle = False)
# resnet        (51200 features)
resnet = torchvision.models.resnet34(pretrained = True)
resnet = torch.nn.DataParallel(resnet.cuda(), args.gpus)
train_feature1, train_label = pre_convolute(resnet, resnet.module.layer4, train_loader) 
valid_feature1, valid_label = pre_convolute(resnet, resnet.module.layer4, valid_loader)
del resnet
torch.cuda.empty_cache()
# inception     (131072 features)
inception = torchvision.models.inception_v3(pretrained = True)
inception.aux_logits = False
inception = torch.nn.DataParallel(inception.cuda(), args.gpus)
train_feature2, _           = pre_convolute(inception, inception.module.Mixed_7c, train_loader) 
valid_feature2, _           = pre_convolute(inception, inception.module.Mixed_7c, valid_loader)
del inception
torch.cuda.empty_cache()
# densenet      (82944 features)
densenet = torchvision.models.densenet121(pretrained = True)
densenet = torch.nn.DataParallel(densenet.cuda(), args.gpus)
train_feature3, _           = pre_convolute(densenet, densenet.module.features, train_loader) 
valid_feature3, _           = pre_convolute(densenet, densenet.module.features, valid_loader)
del densenet
torch.cuda.empty_cache()
# vgg           (41472 features)
vgg = torchvision.models.vgg16(pretrained = True)
vgg = torch.nn.DataParallel(vgg.cuda(), args.gpus)
train_feature4, _           = pre_convolute(vgg, vgg.module.features, train_loader) 
valid_feature4, _           = pre_convolute(vgg, vgg.module.features, valid_loader)
del vgg
torch.cuda.empty_cache()

# Ensemble model -----------------------
class EnsembleFeatureSet(torch.utils.data.Dataset):
    """"""
    def __init__(self, features:list, label):
        super().__init__()
        self.features = features
        self.label = label

    def __len__(self):
        return len(self.label)

    def __getitem__(self, index):
        features = [ f[index] for f in self.features ]
        label = self.label[index]
        return features, label

class EnsembleModel(torch.nn.Module):
    def __init__(self, input_sizes:tuple, hidden_size, num_class):
        super().__init__()
        self.branchs = [ torch.nn.Linear(input_size, hidden_size) for input_size in input_sizes]
        self.dropout = torch.nn.Dropout()
        self.fc = torch.nn.Linear(hidden_size*len(input_sizes), num_class)

    def forward(self, inputs):
        outputs = [ self.branchs[i]( self.dropout(inputs[i]) ) for i in range(len(inputs)) ]
        return self.fc(self.dropout( torch.cat(outputs, dim = 1) ))

train_data2 = EnsembleFeatureSet([train_feature1, train_feature2, train_feature3, train_feature4], train_label)
valid_data2 = EnsembleFeatureSet([valid_feature1, valid_feature2, valid_feature3, valid_feature4], valid_label)
train_loader2 = torch.utils.data.DataLoader(train_data2, args.train_batch, num_workers = len(args.gpus), shuffle = True)
valid_loader2 = torch.utils.data.DataLoader(valid_data2, args.valid_batch, num_workers = len(args.gpus), shuffle = False)

model = EnsembleModel([ len(x) for x in train_data2[0][0] ], 1024, 2)
optimizer = torch.optim.Adam(model.parameters(), lr = args.learning_rate)
_, accuracy = utility.valid(model, valid_loader2, f"Epoch {0:03d} validation")
for epoch in range(args.epochs): #pass
    _, _        = utility.train(model, train_loader2, f"\nEpoch {epoch+1:03d} training  ", optimizer)
    _, accuracy = utility.valid(model, valid_loader2, f"Epoch {epoch+1:03d} validation")


